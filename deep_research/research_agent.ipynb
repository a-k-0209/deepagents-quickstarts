{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc3e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\", override=True)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c897bc9",
   "metadata": {},
   "source": [
    "# Deepagent for Research\n",
    "\n",
    "We will use the `deepagents` package to create a research agent. When using the `deepagents` package, it's important to: \n",
    "\n",
    "1. Understand the native tools available\n",
    "2. Supply task-specific tools\n",
    "3. Supply task-specific instructions\n",
    "4. Supply task-specific sub-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a14c09e",
   "metadata": {},
   "source": [
    "## Task-Specific Tools \n",
    "\n",
    "You can see an overview of the native tools in the [deepagents package README](https://github.com/langchain-ai/deepagents?tab=readme-ov-file#model) as well as the [quickstarts README](https://github.com/langchain-ai/deepagents-quickstarts). We'll extend this with two task-specific tools. \n",
    "\n",
    "### Search Tool \n",
    "\n",
    "There are different search tools that we can use. For example, we can use [Tavily](https://www.tavily.com/) to search for relevant URLs, then fetches the full webpage content.\n",
    "\n",
    "### Think Tool \n",
    "\n",
    "We'll supply a [think tool](https://www.anthropic.com/engineering/claude-think-tool), which is a useful way to help audit agent decision making. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from research_agent.tools import tavily_search, think_tool\n",
    "tools = [tavily_search, think_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba3ee5b",
   "metadata": {},
   "source": [
    "## Task-Specific Instructions\n",
    " \n",
    "Next, let's define task specific instructions using [a few prompting techniques for agents](https://youtu.be/XSZP9GhhuAc?si=zowpViL-2j-vI9hA):\n",
    "\n",
    "### 1. Think Like The Agent\n",
    "What instructions would you give a new work colleague?\n",
    "- **Read the question carefully** - What specific information does the user need?\n",
    "- **Start with broader searches** - Use broad, comprehensive queries first\n",
    "- **After each search, pause and assess** - Do I have enough to answer? What's still missing?\n",
    "- **Execute narrower searches as you gather information** - Fill in the gaps.\n",
    "\n",
    "### 2. Concrete Heuristics (Prevent \"Spin-Out\" on excessive tool calls)\n",
    "Use **Hard Limits** to prevent the research agent from calling tools excessively:\n",
    "- **Stop when you can answer confidently** - Don't keep searching for perfection.\n",
    "- **Give it budgets** - Use 2-3 search tool calls for simple queries. Use up to 5 for complex queries.\n",
    "- **Limit** - Always stop after 5 search tool calls if you cannot find the right source(s).\n",
    "\n",
    "### 3. Show your thinking\n",
    "After each search tool calling, use [`think_tool` to analyze the results](https://www.anthropic.com/engineering/claude-think-tool):\n",
    "- What key information did I find? \n",
    "- What's missing?\n",
    "- Do I have enough to answer the question comprehensively?\n",
    "- Should I search more or provide my answer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4487f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from utils import show_prompt, format_messages\n",
    "from research_agent.prompts import (\n",
    "    RESEARCH_WORKFLOW_INSTRUCTIONS,\n",
    "    TECH_RADAR_WORKFLOW_INSTRUCTIONS,\n",
    "    SUBAGENT_DELEGATION_INSTRUCTIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb7a89-8a26-4fb4-ba77-b05180f2c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_prompt(RESEARCHER_INSTRUCTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ab6e7e",
   "metadata": {},
   "source": [
    "## Task-Specific Sub-Agents\n",
    "\n",
    "You can specify [custom subagents](https://github.com/langchain-ai/deepagents?tab=readme-ov-file#subagents) as a means of context isolation. \n",
    "\n",
    "Here's well define a sub-agent that can search the web for information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6570183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current date\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Create research sub-agent\n",
    "research_sub_agent = {\n",
    "    \"name\": \"research-agent\",\n",
    "    \"description\": \"Delegate research to the sub-agent researcher. Only give this researcher one topic at a time.\",\n",
    "    \"system_prompt\": RESEARCHER_INSTRUCTIONS.format(date=current_date),\n",
    "    \"tools\": [tavily_search, think_tool],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef99f1d",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Now, we can look at all of our instructions together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e55b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limits\n",
    "max_concurrent_research_units = 3\n",
    "max_researcher_iterations = 3\n",
    "\n",
    "# Combine orchestrator instructions (RESEARCHER_INSTRUCTIONS only for sub-agents)\n",
    "INSTRUCTIONS = (\n",
    "    RESEARCH_WORKFLOW_INSTRUCTIONS\n",
    "    + \"\\n\\n\"\n",
    "    + TECH_RADAR_WORKFLOW_INSTRUCTIONS\n",
    "    + \"\\n\\n\"\n",
    "    + \"=\" * 80\n",
    "    + \"\\n\\n\"\n",
    "    + SUBAGENT_DELEGATION_INSTRUCTIONS.format(\n",
    "        max_concurrent_research_units=max_concurrent_research_units,\n",
    "        max_researcher_iterations=max_researcher_iterations,\n",
    "    )\n",
    ")\n",
    "\n",
    "show_prompt(INSTRUCTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6e3639",
   "metadata": {},
   "source": [
    "### Create the agent\n",
    "\n",
    "Now, we create our deepagent with these components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979ff23-e36a-45b2-bd52-03cf4171f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from deepagents import create_deep_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# Model Claude 4.5\n",
    "# model = init_chat_model(model=\"anthropic:claude-sonnet-4-5-20250929\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da8411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent\n",
    "agent = create_deep_agent(\n",
    "      model=model,\n",
    "      tools=tools, \n",
    "      system_prompt=INSTRUCTIONS,\n",
    "      subagents=[research_sub_agent],\n",
    "  )\n",
    "  \n",
    "# Show the agent\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613634c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Build a tech radar for Fast API\",\n",
    "            }\n",
    "        ],\n",
    "    }, \n",
    ")\n",
    "format_messages(result[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188b5ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepagents.backends.utils import file_data_to_string\n",
    "\n",
    "# Convert a specific file to string\n",
    "file_content = file_data_to_string(result[\"files\"]['/final_report.md'])\n",
    "show_prompt(file_content) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc6784",
   "metadata": {},
   "source": [
    "Trace: \n",
    "\n",
    "https://smith.langchain.com/public/72d23852-4616-4bcc-8d8a-b0d1905c945b/r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
